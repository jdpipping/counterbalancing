---
title: "Data Dive"
author: "JP & Dylan Small"
date: "`r Sys.Date()`"
output: html_document
description: "Exploratory data analysis for counterbalance matching"
---

```{r load-packages, include = F}
library(naniar)
library(striprtf)
library(tidyverse)
library(VIM)
```

```{r functions, include = F}

# get variable info from the rtf data dictionary
extract_variable_info = function(rtf_lines) {
  # filter lines that contain variable definitions
  var_lines = rtf_lines[str_detect(rtf_lines, "Variable = ")]
  
  # extract variable info using tidyverse
  map_dfr(var_lines, function(line) {
    # extract variable name and label
    var_name = str_extract(line, "Variable = ([^\\s]+)") |> 
      str_remove("Variable = ")
    
    var_label = str_extract(line, "Variable label = ([^\\r\\n]+)") |> 
      str_remove("Variable label = ")
    
    # only process if we have both name and label
    if (is.na(var_name) || is.na(var_label) || var_name == "" || var_label == "") {
      return(tibble(variable_name = NA_character_, variable_label = NA_character_, sweep = NA_integer_))
    }
    
    # determine sweep from variable label (first digit 0-3 at start)
    sweep = if (str_detect(var_label, "PMS")) {
      0L  # PMS indicates birth sweep
    } else if (str_detect(var_label, "0-3D")) {
      NA_integer_  # 0-3D indicates global variable
    } else {
      str_extract(var_label, "[0-3]") |> 
        as.integer()
    }
    
    # return as data frame row
    tibble(
      variable_name = var_name,
      variable_label = var_label,
      sweep = sweep
    )
  }) |>
    # remove rows with missing information
    filter(!is.na(variable_name), !is.na(variable_label))
}
```

# Data Processing

We read in and clean the two data sources below: the NCDS data for every sweep through age 16 (confounders and treatment) and their age 42 information (outcome). Then, we unify the datasets and identify participants who are eligible for the study.

## NCDS Childhood

The NCDS childhood data contains sweeps at birth, age 7, age 11, and age 16. The age 11 and 16 data is of specific interest to us (confounders and treatment, respectively), so we will filter out the age 7 data and then proceed by cleaning and exploring the data.

```{r childhood-load, message = F}
# load age 0, 7, 11, 16 data
ncds_childhood = read_tsv("../data/raw/ncds-childhood/tab/ncds0123.tab")
# preview
head(ncds_childhood)

# load data dictionary
childhood_dict = read_rtf("../data/raw/ncds-childhood/mrdoc/ukda_data_dictionaries/ncds0123_ukda_data_dictionary.rtf")
```

```{r childhood-info, message = F}
# extract variable information
childhood_info = extract_variable_info(childhood_dict)

# display summary by sweep
cat("variables by sweep:\n")
for (sweep in 0:3) {
  sweep_vars = childhood_info[childhood_info$sweep == sweep, ]
  cat(sprintf("sweep %d (%s): %d variables\n", 
              sweep, 
              c("birth", "age 7", "age 11", "age 16")[sweep + 1],
              nrow(sweep_vars)))
}

# debug: check for NA sweeps
cat("Total variables extracted:", nrow(childhood_info), "\n")
cat("Variables with NA sweep:", sum(is.na(childhood_info$sweep)), "\n")
cat("Variables with valid sweep:", sum(!is.na(childhood_info$sweep)), "\n")

# show first few variables from each sweep
for (sweep in 0:3) {
  sweep_vars = childhood_info[!is.na(childhood_info$sweep) & childhood_info$sweep == sweep, ]
  if (nrow(sweep_vars) > 0) {
    cat(sprintf("\nsweep %d variables (first 5):\n", sweep))
    print(head(sweep_vars, 5))
  }
}

# create final variable mapping
final_var_map = childhood_info[!is.na(childhood_info$sweep), c("variable_name", "sweep", "variable_label")]

# summary by sweep
cat("\nfinal variable count by sweep:\n")
for (sweep in 0:3) {
  sweep_vars = final_var_map[final_var_map$sweep == sweep, ]
  cat(sprintf("sweep %d (%s): %d variables\n", 
              sweep, 
              c("birth", "age 7", "age 11", "age 16")[sweep + 1],
              nrow(sweep_vars)))
}

# get variables for each sweep
birth_vars = final_var_map[final_var_map$sweep == 0, "variable_name"] |> pull()
age7_vars = final_var_map[final_var_map$sweep == 1, "variable_name"] |> pull()
age11_vars = final_var_map[final_var_map$sweep == 2, "variable_name"] |> pull()
age16_vars = final_var_map[final_var_map$sweep == 3, "variable_name"] |> pull()

# display summary
cat("\nvariables available in data by sweep:\n")
cat("birth variables:", length(birth_vars), "\n")
cat("age 7 variables:", length(age7_vars), "\n") 
cat("age 11 variables:", length(age11_vars), "\n")
cat("age 16 variables:", length(age16_vars), "\n")

# show some example variables from each sweep
cat("\nexample variables from each sweep:\n")
for (sweep in 0:3) {
  vars = final_var_map[final_var_map$sweep == sweep, "variable_name"]
  sweep_name = c("birth", "age 7", "age 11", "age 16")[sweep + 1]
  cat(sprintf("%s (first 5): %s\n", sweep_name, 
              paste(head(vars, 5), collapse = ", ")))
}

# create filtered datasets for each sweep
birth_data = ncds_childhood[, c("ncdsid", "n622", birth_vars)]
age7_data = ncds_childhood[, c("ncdsid", "n622", age7_vars)]
age11_data = ncds_childhood[, c("ncdsid", "n622", age11_vars)]
age16_data = ncds_childhood[, c("ncdsid", "n622", age16_vars)]

# basic summary of each sweep's data
cat("\ndata summary by sweep:\n")
cat("birth data dimensions:", dim(birth_data), "\n")
cat("age 7 data dimensions:", dim(age7_data), "\n")
cat("age 11 data dimensions:", dim(age11_data), "\n")
cat("age 16 data dimensions:", dim(age16_data), "\n")

# save childhood data and info
write_csv(ncds_childhood, "../data/processed/ncds-childhood-clean.csv")
write_csv(final_var_map, "../data/processed/ncds-childhood-map.csv")
cat("\nsaved childhood data and variable mapping to ../data/processed/\n")
```

```{r childhood-treatment, message = F}
# define treatment variables from age 16 alcohol consumption
# alcohol consumption variables: n2889, n2890, n2891 (slots 1, 2, 3)

# 1. recode alcohol consumption into standardized units
ncds_childhood = ncds_childhood |>
  mutate(
    alc_slot1 = case_when(
      n2889 == -1           ~  0,         # SPSS-missing or no drinks
      n2889 ==  1           ~  2,         # 2+ measures wine (2 units)
      n2889 ==  2           ~  1,         # 1 measure wine (1 unit)
      n2889 ==  4           ~  1,         # 1 measure spirit (1 unit)
      n2889 ==  5           ~  2,         # 2 measures spirit (2 units)
      n2889 ==  6           ~  3,         # 3 measures spirit (3 units)
      n2889 ==  7           ~  4,         # 4 measures spirit (4 units)
      n2889 ==  8           ~  1,         # half-pint beer (1 unit)
      n2889 ==  9           ~  2,         # 1 pint beer (2 units)
      n2889 == 10           ~  4,         # 2 pints beer (4 units)
      n2889 == 11           ~  6,         # 3 pints beer (6 units)
      n2889 == 12           ~  8,         # 4 pints beer (8 units)
      TRUE                  ~ NA_real_
    ),
    alc_slot2 = case_when(
      n2890 == -1           ~ NA_real_,   # SPSS-missing
      n2890 ==  0           ~  0,         # "No other" in slots 2–3
      n2890 ==  1           ~  2,         # 2+ measures wine (2 units)
      n2890 ==  2           ~  1,         # 1 measure wine (1 unit)
      n2890 ==  4           ~  1,         # 1 measure spirit (1 unit)
      n2890 ==  5           ~  2,         # 2 measures spirit (2 units)
      n2890 ==  6           ~  3,         # 3 measures spirit (3 units)
      n2890 ==  7           ~  4,         # 4 measures spirit (4 units)
      n2890 ==  8           ~  1,         # half-pint beer (1 unit)
      n2890 ==  9           ~  2,         # 1 pint beer (2 units)
      n2890 == 10           ~  4,         # 2 pints beer (4 units)
      n2890 == 11           ~  6,         # 3 pints beer (6 units)
      n2890 == 12           ~  8,         # 4 pints beer (8 units)
      TRUE                  ~ NA_real_
    ),
    alc_slot3 = case_when(
      n2891 == -1           ~ NA_real_,   # SPSS-missing
      n2891 ==  0           ~  0,         # "No other" in slots 2–3
      n2891 ==  1           ~  2,         # 2+ measures wine (2 units)
      n2891 ==  2           ~  1,         # 1 measure wine (1 unit)
      n2891 ==  4           ~  1,         # 1 measure spirit (1 unit)
      n2891 ==  5           ~  2,         # 2 measures spirit (2 units)
      n2891 ==  6           ~  3,         # 3 measures spirit (3 units)
      n2891 ==  7           ~  4,         # 4 measures spirit (4 units)
      n2891 ==  8           ~  1,         # half-pint beer (1 unit)
      n2891 ==  9           ~  2,         # 1 pint beer (2 units)
      n2891 == 10           ~  4,         # 2 pints beer (4 units)
      n2891 == 11           ~  6,         # 3 pints beer (6 units)
      n2891 == 12           ~  8,         # 4 pints beer (8 units)
      TRUE                  ~ NA_real_
    )
  ) |>
  # 2. sum into a continuous treatment
  mutate(
    treatment_cont = case_when(
      is.na(alc_slot1) & is.na(alc_slot2) & is.na(alc_slot3) ~ NA_real_,
      TRUE ~ rowSums(cbind(alc_slot1, alc_slot2, alc_slot3), na.rm = TRUE)
    ),
    # 3. binarize: heavy drinking based on sex-specific thresholds
    treatment_bin = case_when(
      is.na(treatment_cont) ~ NA_real_,  # missing alcohol data
      n622 == 1 & treatment_cont >= 5 ~ 1,  # male, ≥5 units
      n622 == 2 & treatment_cont >= 4 ~ 1,  # female, ≥4 units
      TRUE ~ 0  # not heavy drinking
    )
  )
```

## NCDS Age 42

The NCDS age 42 data is of interest to us because it contains the outcome variable we're interested in: years spent in full-time education. We load and clean the data, but we will wait to explore the data until after we've set up the observational study.

```{r age42-load, message=FALSE}
# load age 42 data
ncds_42 = read_tsv("../data/raw/ncds-42/tab/ncds6_v2.tab")
# preview
head(ncds_42)

# load age 42 data dictionary
age42_dict = read_rtf("../data/raw/ncds-42/mrdoc/ncds6_v2_ukda_data_dictionary.rtf")
```

```{r age42-info, message = F}
# extract variable information (all variables are sweep 4 - age 42)
age42_info = extract_variable_info(age42_dict) |>
  mutate(sweep = 4L)  # all variables are from age 42 sweep

# display summary
cat("age 42 variables:", nrow(age42_info), "\n")
cat("first 5 variables:\n")
print(head(age42_info, 5))

# get age 42 variables
age42_vars = age42_info$variable_name

# display summary
cat("\nage 42 variables available in data:", length(age42_vars), "\n")
cat("example variables (first 5):", paste(head(age42_vars, 5), collapse = ", "), "\n")

# save age 42 data and info
write_csv(ncds_42, "../data/processed/ncds-42-clean.csv")
write_csv(age42_info, "../data/processed/ncds-42-map.csv")
cat("\nsaved age 42 data and variable mapping to ../data/processed/\n")
```

## Unified Dataset

Now that we have the childhood and age 42 data, we can unify them into a single dataset and identify which units are eligible for the study.

```{r merge-datasets, message = F}
# merge childhood and age 42 datasets by participant id
ncds_merged = ncds_childhood |>
  # drop out participants missing from either set
  inner_join(ncds_42, by = "ncdsid")

# display summary of merged dataset
merge_summary = tibble(
  description = c("childhood data participants", "age 42 data participants", "merged dataset participants", "missing from age 42", "only in age 42"),
  count = c(nrow(ncds_childhood), nrow(ncds_42), nrow(ncds_merged), 
            nrow(ncds_childhood |> anti_join(ncds_42, by = "ncdsid")),
            nrow(ncds_42 |> anti_join(ncds_childhood, by = "ncdsid")))
)

print("Dataset merge summary:")
print(merge_summary)

# create a summary of participation across sweeps
participation_summary = ncds_merged |>
  summarise(
    total_participants = n(),
    with_birth_data = sum(!is.na(n622)),  # sex variable from birth
    with_age7_data = sum(!is.na(n94)),    # example age 7 variable
    with_age11_data = sum(!is.na(n2region)), # region at age 11
    with_age16_data = sum(!is.na(n3region)), # region at age 16
    with_age42_data = sum(!is.na(ncdsid))    # all have ncdsid
  ) |>
  pivot_longer(everything(), names_to = "sweep", values_to = "participants") |>
  mutate(sweep = str_remove(sweep, "with_") |> str_replace("_data", ""))

print("Participation summary by sweep:")
print(participation_summary)

print("First few rows of merged dataset (first 10 columns):")
print(head(ncds_merged[, 1:10]))

# save merged dataset
write_csv(ncds_merged, "../data/processed/ncds-merged-clean.csv")
cat("\nsaved merged dataset to ../data/processed/ncds-merged-clean.csv\n")
```

# Data Exploration

Now, we will explore the *un-merged* dataset of eligible participants to ensure we don't bias our findings.

```{r eligible-participants, message = F}
# identify eligible participants (those with treatment data in merged set)
eligible_participant_ids = ncds_merged |>
  filter(!is.na(treatment_bin)) |>
  pull(ncdsid)

print("Eligible participants summary:")
print(paste("Total eligible participants:", length(eligible_participant_ids)))

# filter childhood dataset for eligible participants
ncds_childhood_eligible = ncds_childhood |>
  filter(ncdsid %in% eligible_participant_ids)
# filter age 42 dataset for eligible participants
ncds_42_eligible = ncds_42 |> 
  filter(ncdsid %in% eligible_participant_ids)

print("Dataset prepared for analysis:")
print(paste("Eligible participants:", nrow(ncds_childhood_eligible)))

# save eligible datasets
write_csv(ncds_childhood_eligible, "../data/processed/ncds-childhood-eligible.csv")
write_csv(ncds_42_eligible, "../data/processed/ncds-42-eligible.csv")
cat("\nsaved eligible datasets to ../data/processed/\n")
```

```{r missingness, message = F}
# Comprehensive missing data patterns analysis
print("=== MISSING DATA ANALYSIS ===")

# calculate missingness for all variables
missing_all = ncds_childhood_eligible |>
  summarise(across(everything(), ~sum(is.na(.))/n()*100)) |>
  pivot_longer(everything(), names_to = "variable", values_to = "missing_pct") |>
  arrange(desc(missing_pct))

# identify sweep for each variable
var_sweeps = tibble(
  variable = missing_all$variable,
  sweep = case_when(
    variable %in% birth_vars ~ "birth",
    variable %in% age7_vars ~ "age7", 
    variable %in% age11_vars ~ "age11",
    variable %in% age16_vars ~ "age16",
    TRUE ~ "unknown"
  )
)

# 1. Overall missingness patterns across ALL variables
print("1. OVERALL MISSINGNESS PATTERNS")

print("Missingness summary across all variables:")
print(paste("Total variables analyzed:", nrow(missing_all)))
print(paste("Variables with >50% missing:", sum(missing_all$missing_pct > 50)))
print(paste("Variables with >30% missing:", sum(missing_all$missing_pct > 30)))
print(paste("Variables with >10% missing:", sum(missing_all$missing_pct > 10)))

# show distribution of missingness
missing_dist = missing_all |>
  summarise(
    mean_missing = mean(missing_pct),
    median_missing = median(missing_pct),
    q25 = quantile(missing_pct, 0.25),
    q75 = quantile(missing_pct, 0.75)
  )

print("\nMissingness distribution:")
print(missing_dist)

# 2. Missingness by sweep (age)
print("\n2. MISSINGNESS BY SWEEP")

# analyze missingness by sweep
missing_by_sweep = missing_all |>
  left_join(var_sweeps, by = "variable") |>
  group_by(sweep) |>
  summarise(
    n_vars = n(),
    mean_missing = mean(missing_pct),
    median_missing = median(missing_pct),
    high_missing = sum(missing_pct > 50)
  ) |>
  arrange(desc(mean_missing))

print("Missingness by sweep:")
print(missing_by_sweep)



# 4. Treatment variables missingness
print("\n4. TREATMENT VARIABLES MISSINGNESS")

treatment_vars = c("alc_slot1", "alc_slot2", "alc_slot3", "treatment_cont", "treatment_bin")
treatment_missing = ncds_childhood_eligible |>
  select(all_of(treatment_vars)) |>
  summarise(across(everything(), ~sum(is.na(.))/n()*100)) |>
  pivot_longer(everything(), names_to = "variable", values_to = "missing_pct")

print("Missing percentage in treatment variables:")
print(treatment_missing)

# 5. Missingness patterns by treatment status
print("\n5. MISSINGNESS PATTERNS BY TREATMENT STATUS")

# analyze missingness differences between treatment groups
treatment_missing_patterns = ncds_childhood_eligible |>
  filter(!is.na(treatment_bin)) |>
  select(treatment_bin, all_of(missing_all$variable[1:100])) |>  # analyze first 100 vars for efficiency
  group_by(treatment_bin) |>
  summarise(across(everything(), ~sum(is.na(.))/n()*100)) |>
  pivot_longer(-treatment_bin, names_to = "variable", values_to = "missing_pct") |>
  pivot_wider(names_from = treatment_bin, values_from = missing_pct, 
              names_prefix = "missing_group_") |>
  mutate(
    missing_diff = missing_group_1 - missing_group_0,
    abs_missing_diff = abs(missing_diff)
  ) |>
  arrange(desc(abs_missing_diff))

print("Variables with largest missingness differences between treatment groups:")
print(head(treatment_missing_patterns, 15))

# identify variables with significant missingness differences
significant_missing_diff = treatment_missing_patterns |>
  filter(abs_missing_diff > 5)  # 5 percentage point difference

print(paste("\nVariables with >5% missingness difference between treatment groups:", nrow(significant_missing_diff)))

# 6. Correlation patterns in missingness
print("\n6. CORRELATION PATTERNS IN MISSINGNESS")

# create missingness indicator matrix
missing_indicators = ncds_childhood_eligible |>
  select(all_of(all_vars[1:50])) |>  # use subset for computational efficiency
  mutate(across(everything(), ~ifelse(is.na(.), 1, 0)))

# calculate correlation of missingness patterns
missing_cor = missing_indicators |>
  cor(method = "spearman")

# find variables with similar missingness patterns
high_missing_cor = which(abs(missing_cor) > 0.7 & missing_cor != 1, arr.ind = TRUE)
if (nrow(high_missing_cor) > 0) {
  missing_cor_pairs = data.frame(
    var1 = rownames(missing_cor)[high_missing_cor[,1]],
    var2 = colnames(missing_cor)[high_missing_cor[,2]],
    correlation = missing_cor[high_missing_cor]
  ) |>
    arrange(desc(abs(correlation)))
  
  print("Variable pairs with similar missingness patterns (|r| > 0.7):")
  print(head(missing_cor_pairs, 10))
} else {
  print("No highly correlated missingness patterns found")
}

# 7. Variable selection recommendations
print("\n7. VARIABLE SELECTION RECOMMENDATIONS")

# identify variables suitable for analysis
suitable_vars = missing_all |>
  filter(missing_pct <= 30)

print("Variables suitable for primary analysis (≤30% missing):")
print(paste("Total suitable variables:", nrow(suitable_vars)))

# identify variables for sensitivity analysis
sensitivity_vars = missing_all |>
  filter(missing_pct > 30 & missing_pct <= 50)

print("\nVariables for sensitivity analysis (30-50% missing):")
print(paste("Total sensitivity variables:", nrow(sensitivity_vars)))

# identify variables to exclude
exclude_vars = missing_all |>
  filter(missing_pct > 50)

print("\nVariables to exclude (>50% missing):")
print(paste("Total excluded variables:", nrow(exclude_vars)))
```

```{r key-variables, message = F}
# Key variables exploration for causal inference
print("=== KEY VARIABLES EXPLORATION ===")

# 1. Treatment: Heavy drinking at age 16
print("Treatment: Heavy drinking at age 16 (≥5 units males, ≥4 units females)")

# 2. Confounder variables (age 11)
confounder_candidates = age11_vars[str_detect(age11_vars, regex("region|class|income|family|parent|socio|aspiration", ignore_case = TRUE))]
print("\nPotential confounder variables (age 11):")
print(head(confounder_candidates, 10))

# 3. Outcome variables (age 42)
outcome_candidates = age42_vars[str_detect(age42_vars, regex("education|school|qualification|degree", ignore_case = TRUE))]
print("\nPotential outcome variables (age 42):")
print(head(outcome_candidates, 10))

# 4. Basic demographics
demographics = ncds_childhood_eligible |>
  summarise(
    total = n(),
    male = sum(n622 == 1, na.rm = TRUE),
    female = sum(n622 == 2, na.rm = TRUE),
    missing_sex = sum(is.na(n622))
  ) |>
  mutate(
    male_pct = male / total,
    female_pct = female / total,
    missing_sex_pct = missing_sex / total
  )

print("\nDemographics of eligible participants:")
print(demographics)
```

```{r treatment, message = F}
# Treatment variable exploration
print("=== TREATMENT VARIABLE EXPLORATION ===")

# display treatment summary
treatment_summary = ncds_childhood_eligible |>
  summarise(
    total_participants = n(),
    with_alcohol_data = sum(!is.na(treatment_cont)),
    heavy_drinkers = sum(treatment_bin == 1, na.rm = TRUE),
    not_heavy_drinkers = sum(treatment_bin == 0, na.rm = TRUE),
    missing_treatment = sum(is.na(treatment_bin))
  ) |>
  mutate(
    heavy_drinking_pct = heavy_drinkers / with_alcohol_data,
    not_heavy_drinking_pct = not_heavy_drinkers / with_alcohol_data,
    missing_pct = missing_treatment / total_participants
  )

print("Heavy drinking treatment summary:")
print(treatment_summary)

# display continuous alcohol consumption distribution
alcohol_dist = ncds_childhood_eligible |>
  filter(!is.na(treatment_cont)) |>
  summarise(
    mean_units = mean(treatment_cont),
    median_units = median(treatment_cont),
    sd_units = sd(treatment_cont),
    min_units = min(treatment_cont),
    max_units = max(treatment_cont)
  )

print("\nAlcohol consumption distribution (units per week):")
print(alcohol_dist)

# treatment by sex
treatment_by_sex = ncds_childhood_eligible |>
  filter(!is.na(treatment_bin) & !is.na(n622)) |>
  group_by(n622) |>
  summarise(
    total = n(),
    heavy_drinkers = sum(treatment_bin == 1),
    heavy_drinking_pct = heavy_drinkers / total
  ) |>
  mutate(sex = case_when(n622 == 1 ~ "Male", n622 == 2 ~ "Female"))

print("\nHeavy drinking by sex:")
print(treatment_by_sex)
```

```{r high-dimensional, message = F}
# High-dimensional causal inference exploration strategies
print("=== HIGH-DIMENSIONAL EXPLORATION STRATEGIES ===")

# 1. Variable clustering by correlation structure
print("1. CORRELATION-BASED VARIABLE CLUSTERING")

# use pre-calculated missingness to select variables with sufficient data
confounder_subset = missing_all |>
  left_join(var_sweeps, by = "variable") |>
  filter(sweep == "age11" & missing_pct <= 30) |>  # age 11 variables with ≤30% missing
  pull(variable) |>
  head(50)  # limit to 50 for computational efficiency

confounder_data = ncds_childhood_eligible |>
  select(all_of(confounder_subset)) |>
  drop_na()  # use complete cases for correlation analysis

# compute correlation matrix
confounder_cor = confounder_data |>
  cor(use = "pairwise.complete.obs", method = "spearman")

# find highly correlated variable groups
high_cor_pairs = which(abs(confounder_cor) > 0.7 & confounder_cor != 1, arr.ind = TRUE)
if (nrow(high_cor_pairs) > 0) {
  high_cor_vars = data.frame(
    var1 = rownames(confounder_cor)[high_cor_pairs[,1]],
    var2 = colnames(confounder_cor)[high_cor_pairs[,2]],
    correlation = confounder_cor[high_cor_pairs]
  ) |>
    arrange(desc(abs(correlation)))
  
  print("Highly correlated variable pairs (|r| > 0.7):")
  print(head(high_cor_vars, 10))
} else {
  print("No highly correlated pairs found in this subset")
}

# 2. Principal component analysis for dimensionality reduction
print("\n2. PRINCIPAL COMPONENT ANALYSIS")

# use same confounder subset for PCA
pca_data = ncds_childhood_eligible |>
  select(all_of(confounder_subset)) |>
  drop_na()  # use complete cases for PCA

if (nrow(pca_data) > 0) {
  # perform PCA
  pca_result = prcomp(pca_data, scale = TRUE, center = TRUE)
  
  # variance explained
  var_explained = pca_result$sdev^2 / sum(pca_result$sdev^2)
  cum_var_explained = cumsum(var_explained)
  
  print("Variance explained by first 10 principal components:")
  pca_summary = data.frame(
    component = 1:10,
    variance_explained = var_explained[1:10],
    cumulative_variance = cum_var_explained[1:10]
  )
  print(pca_summary)
  
  # variables with highest loadings on first few components
  loadings = pca_result$rotation[, 1:3]
  top_loadings = data.frame(
    variable = rownames(loadings),
    pc1_loading = loadings[,1],
    pc2_loading = loadings[,2],
    pc3_loading = loadings[,3]
  ) |>
    arrange(desc(abs(pc1_loading)))
  
  print("\nTop 10 variables by PC1 loading:")
  print(head(top_loadings, 10))
}

# 3. Treatment-confounder balance assessment
print("\n3. TREATMENT-CONFOUNDER BALANCE ASSESSMENT")

# select key confounders for balance testing (use variables that exist)
key_confounders = c("n2region")  # start with just region, add more as needed
# check which key confounders exist in the data
existing_confounders = key_confounders[key_confounders %in% names(ncds_childhood_eligible)]

if (length(existing_confounders) > 0) {
  balance_data = ncds_childhood_eligible |>
    filter(!is.na(treatment_bin)) |>
    select(ncdsid, treatment_bin, all_of(existing_confounders)) |>
    drop_na()

  if (nrow(balance_data) > 0) {
  # standardized mean differences
  balance_summary = balance_data |>
    group_by(treatment_bin) |>
    summarise(across(all_of(existing_confounders), 
                    list(mean = ~mean(., na.rm = TRUE), 
                         sd = ~sd(., na.rm = TRUE)))) |>
    pivot_longer(-treatment_bin, names_to = "variable", values_to = "value") |>
    separate(variable, into = c("var", "stat"), sep = "_") |>
    pivot_wider(names_from = stat, values_from = value) |>
    pivot_wider(names_from = treatment_bin, values_from = c(mean, sd), 
                names_prefix = "group_") |>
    mutate(
      std_diff = (mean_group_1 - mean_group_0) / sqrt((sd_group_1^2 + sd_group_0^2) / 2)
    )
  
  print("Standardized mean differences (treatment vs control):")
  print(balance_summary)
  }
} else {
  print("No key confounders found in the data for balance testing")
}

# 4. Variable importance for treatment prediction
print("\n4. VARIABLE IMPORTANCE FOR TREATMENT PREDICTION")

# use random forest to identify important variables for predicting treatment
library(randomForest)

# prepare data for variable importance analysis
importance_data = ncds_childhood_eligible |>
  filter(!is.na(treatment_bin)) |>
  select(treatment_bin, all_of(confounder_subset)) |>
  drop_na()  # use complete cases for random forest

if (nrow(importance_data) > 0 && ncol(importance_data) > 1) {
  # fit random forest
  rf_model = randomForest(as.factor(treatment_bin) ~ ., 
                         data = importance_data, 
                         importance = TRUE,
                         ntree = 100)
  
  # extract variable importance
  var_importance = importance(rf_model) |>
    as.data.frame() |>
    rownames_to_column("variable") |>
    arrange(desc(MeanDecreaseAccuracy)) |>
    head(15)
  
  print("Top 15 variables by importance for predicting treatment:")
  print(var_importance)
}

# 5. Missing data patterns and mechanisms
print("\n5. MISSING DATA PATTERNS")

# analyze missing data patterns by treatment group
missing_patterns = ncds_childhood_eligible |>
  filter(!is.na(treatment_bin)) |>
  select(treatment_bin, all_of(confounder_subset[1:20])) |>
  group_by(treatment_bin) |>
  summarise(across(everything(), ~sum(is.na(.))/n()*100)) |>
  pivot_longer(-treatment_bin, names_to = "variable", values_to = "missing_pct") |>
  pivot_wider(names_from = treatment_bin, values_from = missing_pct, 
              names_prefix = "missing_group_") |>
  mutate(missing_diff = missing_group_1 - missing_group_0) |>
  arrange(desc(abs(missing_diff)))

print("Missing data differences between treatment groups (top 10):")
print(head(missing_patterns, 10))



# 7. Outcome variable exploration
print("\n7. OUTCOME VARIABLE EXPLORATION")

# identify potential outcome variables
outcome_candidates = age42_vars[str_detect(age42_vars, regex("education|school|qualification|degree|income|occupation", ignore_case = TRUE))]

print("Potential outcome variables by domain:")
outcome_domains = list(
  education = outcome_candidates[str_detect(outcome_candidates, regex("education|school|qualification|degree", ignore_case = TRUE))],
  economic = outcome_candidates[str_detect(outcome_candidates, regex("income|occupation|employment|earnings", ignore_case = TRUE))],
  health = outcome_candidates[str_detect(outcome_candidates, regex("health|medical|disability", ignore_case = TRUE))]
)

map_dfr(outcome_domains, function(vars) {
  tibble(
    domain = names(outcome_domains)[which(outcome_domains == vars)],
    n_variables = length(vars),
    example_vars = paste(head(vars, 3), collapse = ", ")
  )
}, .id = "domain") |>
  print()
```